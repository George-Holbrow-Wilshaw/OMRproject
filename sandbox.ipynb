{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imageio \n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import color\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class primusSequence:\n",
    "\n",
    "    def __init__(self, folder, package):\n",
    "        self.image = imageio.imread(\"./data/\" + package + \"/\" + folder + \"/\" + folder + \".png\")\n",
    "        self.semantic = open(\"./data/\" + package + \"/\" + folder + \"/\" + folder + \".semantic\").read()\n",
    "        self.labels = re.findall(r'note\\-(.+?)\\_', self.semantic)\n",
    "        \n",
    "    def flattened_image(self):\n",
    "        im = self.image\n",
    "        return(im.flatten())\n",
    "                                    \n",
    "        \n",
    "def init_objs(dataset):\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        ROOT = './data/package_aa/'\n",
    "        package = 'package_aa'\n",
    "    elif dataset == 'validate':\n",
    "        ROOT = './data/package_ab/'\n",
    "        package = 'package_ab'\n",
    "\n",
    "    folders = [directory for directory in os.listdir(ROOT) if os.path.isdir(ROOT+directory)]\n",
    "    objs = []\n",
    "    \n",
    "    for f in folders:\n",
    "        objs.append(primusSequence(f, package))\n",
    "        \n",
    "    return(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = init_objs('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = ['a', 'b'] * 21797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/George/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pitch(pitch):\n",
    "    \n",
    "    m = {\"a\": 0,\n",
    "         \"h\": 1,\n",
    "         \"c1\": 2,\n",
    "         \"d1\": 3,\n",
    "         \"e1\": 4,\n",
    "         \"f1\": 5,\n",
    "         \"g1\": 6,\n",
    "         \"a1\": 0,\n",
    "         \"h1\": 1,\n",
    "         \"c2\": 2,\n",
    "         \"d2\": 3,\n",
    "         \"e2\": 4,\n",
    "         \"f2\": 5,\n",
    "         \"g2\": 6,\n",
    "         \"a2\": 0,\n",
    "         \"h2\": 1,\n",
    "         \"c3\": 2,\n",
    "         \"other\": 7}\n",
    "    \n",
    "    return(m[pitch])\n",
    "\n",
    "class ViennaNote:\n",
    "    \n",
    "    def __init__(self, fn, typ):\n",
    "        attr = fn.split('-')\n",
    "        \n",
    "        if typ == 'test':\n",
    "            ROOT = './data/originals-test/'\n",
    "        elif typ == 'train':\n",
    "            ROOT = './data/transformations-resized/'\n",
    "        else:\n",
    "            sys.exit()\n",
    "            \n",
    "        self.type = attr[0]\n",
    "        self.time = attr[1]\n",
    "        self.pitch = attr[2]\n",
    "        imfile = imageio.imread(ROOT + fn)\n",
    "        self.image = color.rgb2gray(imfile) / 255\n",
    "        \n",
    "    def resize_image(self, width, height):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class InputData:\n",
    "    \n",
    "    ROOT = './data/transformations-resized/' \n",
    "    \n",
    "    def __init__(self, path = ROOT):\n",
    "        self.files = [file for file in os.listdir(path) if os.path.isfile(path + file) and file[0:4] == 'note']\n",
    "        self.objs = [ViennaNote(f, 'train') for f in self.files]\n",
    "                \n",
    "    def training_images(self, path = ROOT):\n",
    "        images = [o.image for o in self.objs]\n",
    "        return(np.array(images))\n",
    "    \n",
    "    def training_labels(self, path = ROOT):\n",
    "        notes = [o.pitch for o in self.objs]\n",
    "        labels = [map_pitch(pitch) for pitch in notes]\n",
    "        return(np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = InputData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input_data.training_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39264, 50, 30)"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.training_images().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = input_data.training_images().reshape(39264, 50, 30, 1)\n",
    "train_labels = input_data.training_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(3, 5, input_shape=(50, 30, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(input_shape = (50, 30, 1)),\n",
    "    tf.keras.layers.Dense(800, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(160, activation=tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "859/859 [==============================] - 22s 26ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0294 - val_accuracy: 0.9912\n",
      "Epoch 2/5\n",
      "859/859 [==============================] - 28s 33ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0155 - val_accuracy: 0.9947\n",
      "Epoch 3/5\n",
      "859/859 [==============================] - 29s 34ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0084 - val_accuracy: 0.9975\n",
      "Epoch 4/5\n",
      "859/859 [==============================] - 27s 31ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0198 - val_accuracy: 0.9948\n",
      "Epoch 5/5\n",
      "859/859 [==============================] - 28s 33ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0081 - val_accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x8bd98e1d0>"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels)\n",
    "\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          validation_split=0.3,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 46, 26, 3)         78        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 13, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_99 (Flatten)         (None, 897)               0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 800)               718400    \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 160)               128160    \n",
      "=================================================================\n",
      "Total params: 846,638\n",
      "Trainable params: 846,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3272,)"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x88680ff80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/George/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 4, 0, 0, 2, 4, 4, 2, 2, 0, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = imageio.imread('./data/originals-resized/note-eighth-f1-3159.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = color.rgb2gray(test_image) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = input_data.training_images()[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 50, 30)"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViennaNote:\n",
    "    \n",
    "    def __init__(self, fn, typ):\n",
    "        attr = fn.split('-')\n",
    "        \n",
    "        if typ == 'test':\n",
    "            ROOT = './data/originals-test/'\n",
    "        elif typ == 'train':\n",
    "            ROOT = './data/originals-resized/'\n",
    "        else:\n",
    "            sys.exit()\n",
    "            \n",
    "        self.type = attr[0]\n",
    "        self.time = attr[1]\n",
    "        self.pitch = attr[2]\n",
    "        imfile = imageio.imread('./data/originals-test/' + fn)\n",
    "        self.image = color.rgb2gray(imfile) / 255\n",
    "        \n",
    "    def resize_image(self, width, height):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class TestData:\n",
    "    \n",
    "    ROOT = './data/originals-test/' \n",
    "    \n",
    "    def __init__(self, path = ROOT):\n",
    "        self.files = [file for file in os.listdir(path) if os.path.isfile(path + file) and file[0:4] == 'note']\n",
    "        self.objs = [ViennaNote(f, 'test') for f in self.files]\n",
    "                \n",
    "    def training_images(self, path = ROOT):\n",
    "        images = [o.image for o in self.objs]\n",
    "        return(np.array(images))\n",
    "    \n",
    "    def training_labels(self, path = ROOT):\n",
    "        notes = [o.pitch for o in self.objs]\n",
    "        labels = [map_pitch(pitch) for pitch in notes]\n",
    "        return(np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TestData().training_images().reshape(16, 50, 30, 1)\n",
    "labs = TestData().training_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 4, 0, 0, 2, 4, 3, 2, 3, 0, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1ccfc49a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 4, 0, 0, 2, 4, 3, 2, 3, 0, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
